{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample background \n",
    "\n",
    "Individual guano samples were processed in two separate sequencing runs. See Jupyter notebooks titled \"bri-P1-notes\" and \"bri-P2-notes\" for initial processing details. This notebook functions by beginning with concatenating individually completed sequencing fastq files, removing any required reads associated for samples within those files we want to discard, then continuing with the clustering of all reads without the mock community. Index-bleed filters and auto-subtract values are assigned to this common pool of clustered reads using the more conservative when applicable. See below for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Running core programs:\n",
    "    - AMPtk 0.8.6\n",
    "    - vsearch v2.3.4_linux_x86_64\n",
    "    - usearch usearch v9.2.64_i86linux32\n",
    "    - python 2.7.6\n",
    "- Installed the necessary (COI) databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final cleanups before OTU clustering\n",
    "\n",
    "#### Concatenating\n",
    "The samples from Project1 and Project2 were combined by concatenating the two files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to concatenate two {}.demux.fq files\n",
    "cat \\\n",
    "/leo/devon/projects/guano/bri2016/p1_data/bri-chunk1/cleaned.demux.fq \\\n",
    "/leo/devon/projects/guano/bri2016/p2_data/bridropd.demux.fq > prebriall.demux.fq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample read removal\n",
    "Initially when completing the analyses on the individual sequencing runs, samples in Project1 with more than 5,000 reads were kept while samples in Project2 were kept with 10,000 reads (for various reasons including NTC read depth, mock community contamination, etc.) I wanted to be unifrom as possible when combining the two datasets and went with a more conservative approach by requiring 10,000 reads for any sample in this project. Therefore, 28 additional samples from Project1 were dropped, as listed in the file **morefiles2drop.txt**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amptk remove -i prebriall.demux.fq -f morefiles2drop.txt -o briall.demux.fq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of samples following concatenation between both projects is **210 samples**. We are highly confident that these samples contain a meaningful number of reads to ensure that our community analyses are robust, while also containing as little type-1 error as possible in the forthcoming OTU table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 2 - OTU clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to cluster P1L1 data:\n",
    "amptk dada2 \\\n",
    "--fastq briall.demux.fq \\\n",
    "--out briall \\\n",
    "--length 180 \\\n",
    "--platform illumina \\\n",
    "--uchime_ref COI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the output using the default settings with DADA2:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "[10:06:33 AM]: 13,151,134 reads passed\n",
    "[11:46:51 AM]: 7,671 total inferred sequences (iSeqs)\n",
    "[11:46:51 AM]: 5,036 denovo chimeras removed\n",
    "[11:46:51 AM]: 2,635 valid iSeqs\n",
    "[11:47:04 AM]: 2,537 iSeqs passed, 98 ref chimeras removed\n",
    "[12:34:15 PM]: 13,059,451 reads mapped to iSeqs (98%)\n",
    "[12:34:17 PM]: 1,662 OTUs generated\n",
    "[01:14:46 PM]: 13,017,444 reads mapped to OTUs (98%)\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is to filter the OTU table with the fasta file listed above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: filtering OTU table\n",
    "\n",
    "Note that there is something a bit unique about this analysis: the two independent sequencing runs (P1 and P2) each had their own mock communities; normally I'd take the more conservative estimate from either run and then apply that here, but there were some subtleties that required keeping the mock community in this dataset. These are going to be analyzed now to determine a few factors:  \n",
    "\n",
    "1. What's the **index-bleed** threshold we want to apply? \n",
    "    Earlier work from the independent runs suggested somewhere between 0.1 - 0.3%\n",
    "\n",
    "2. What's the **subtract** threshold we want to apply?\n",
    "    Independent sequencing runs reported values of 47 and 86; thus the more conservative measure would be 86. However, this higher value (from Project 1 sequencing run) allowed for three non-intended OTUs to remain in the dataset in low values; it's unclear whether these are the result of index-bleed from actual *BRI samples*, or from another sample placed on the same P1 lane (for example, from O'Rourke samples, or others), or if it's from low-level contamination that was incorporated at the PCR step earlier in the workflow.  \n",
    "\n",
    "3. How many OTUs will be dropped if necessary to balance the **subtract** value with overall OTU retention?  \n",
    "\n",
    "To address these questions we'll run preliminary filtering steps and assess their output, as described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amptk filter \\\n",
    "-i briall.cluster.otu_table.txt \\\n",
    "-f briall.cluster.otus.fa \\\n",
    "-b mockIM3 \\\n",
    "--keep_mock \\\n",
    "--calculate in \\\n",
    "--mc /leo/devon/projects/guano/mock-fa/CFMR_insect_mock3.fa \\\n",
    "--debug \\\n",
    "--subtract auto \\\n",
    "-o testfilt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the relevant output:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "[01:32:01 PM]: OTU table contains 1662 OTUs\n",
    "[01:32:03 PM]: Index bleed, samples into mock: 1.405000%.\n",
    "[01:32:03 PM]: Auto subtract filter set to 977\n",
    "[01:32:09 PM]: Filtering OTU table down to 406 OTUs\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, we have a pretty high index bleed (but not awful), but a HUGE **subtract** value. From earlier work on each sequencing runs (P1 and P2), this is likely due to a handful of samples. To address which samples contain the highest number of reads, see the basic notes outlined in \"bri-P2-notes\". Bioinformatic steps and subsequent results are briefly explained below.  \n",
    "\n",
    "First, identifying the number of contaminant OTUs in our combined mock community:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sed -i 's/#OTU ID/OTUid/' testfilt.final.txt\n",
    "sed -i 's/#OTU ID/OTUid/' testfilt.normalized.num.txt\n",
    "awk -F '\\t' '{print NF; exit}' testfilt.final.txt\n",
    "    #212\n",
    "\n",
    "cut testfilt.normalized.num.txt -f 1,211 | sort -k2,2n | awk '$2 != \"0.0\" {print $0}'\n",
    "    #OTU249 is the culprit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above script produces a long list (see below) of all OTUs present in our mock community, though nearly all of these unwanted OTUs are in very low abundance (while, importantly, all the OTUs that should be in our mock community are there in relatively high numbers). Note, however, one OTU (OTU249) contains a much higher number of reads than any other unwanted OTU. This is in one sense reassuring, as it implies that the high **subtract** value found in our first-pass filtering step is due to just a single OTU, and by dropping just that one OTU we sould be able to retain far more reads/OTUs when our final filter is applied.  \n",
    "\n",
    "- ...*(more values in list containing OTUs with fewer than 36.0 reads)*...\n",
    "- OTU497\t36.0\n",
    "- OTU151\t41.0\n",
    "- OTU21\t48.0\n",
    "- MockIM34_pident=100.0_OTU349\t682.0\n",
    "- **OTU249\t977.0**\n",
    "- MockIM49_pident=100.0_OTU207\t3960.0\n",
    "- MockIM6_pident=100.0_OTU188\t4976.0\n",
    "- MockIM15_pident=99.4_OTU161\t7036.0  \n",
    "\n",
    "The next question is whether or not **OTU249** persists among many samples in addition to our mock community:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grep \"\\\\bOTU249\\\\b\" testfilt.normalized.num.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result indicates that OTU249 is highest in our mock community (recall it's value was **977** reads); only 14 other samples have more than 100 reads (most are 0.0). Average was ~31, but deviation was about 119. See **otu249counts.txt** for table of these counts. I further investigated whether or not there was any relationship for a particular factor (index, PCR or DNA plate/well, etc.) associated with contamination; there doesn't appear to be one among the most contaminated. See **otu249contamtable.txt** for these results.  \n",
    "\n",
    "To ensure this OTU is likely the same contaminant observed in individual analyses performed earlier, a BLAST search was performed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grep \"\\\\bOTU249\\\\b\" briall.cluster.otus.fa -A 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alignment results indicate it's Fannia canicularis, the Lesser housefly, which was what was observed from earlier independent analyses for the P1 data set. It's unclear whether contamination was from index bleed from other samples not part of this dataset (ex. other bird sequencing projects), or from primer contamination. Regardless, dropping this one OTU is likely of little consequence to broader interpretation as it is not particularly common in our dataset.  \n",
    "\n",
    "To remove OTU249:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amptk drop \\\n",
    "-i briall.cluster.otus.fa \\\n",
    "-r briall.demux.fq \\\n",
    "-l OTU249 \\\n",
    "-o bri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above steps likely address the problem of OTU contamination in our mock community. However, there is a single negative control in this dataset that should be dropped - sample \"**negbri-41C03**\". This sample wasn't removed initially because it's useful to notice how many OTUs are present, and to what degree (in terms of relative/normalized reads). In certain cases where negative controls show some appreciable number of amidst true samples, we find that a single OTU or two should be dropped from all samples (like above). However, this sample doesn't appear to be a typical cross-contamination event; rather, I think this sample represents one of two scenarios:  \n",
    "- (a) A guano sample placed in an adjacent well split and fell into this negative control well, and thus represents a pseudoreplicate.\n",
    "- (b) A guano sample was misplaced directly into the negative control well, and thus represents a true sample that is simply mislabeled.  \n",
    "\n",
    "A quick analysis of this sample suggests the following:  \n",
    "1. There is a single OTU that contains the majority of the reads associated with this sample: OTU2 (see file **negconcounts.txt** for all OTU counts associated with this sample). This OTU exists in just a handful of all true samples, with only 7 samples containing >100 reads (though 5 samples contain >10,000 reads). Thus this OTU best aligns to one of two *crane flys*, which are fairly large and may take up a significant proportion of a single guano sample.\n",
    "2. There are just 5 other OTUs that contain >100 reads:\n",
    "    - OTU48, OTU154, OTU34 follow the similar pattern above: only a few samples contain many reads associated with this particular OTU, and there's a huge variance in total number of reads. \n",
    "    - OTU48 is another crane fly; OTU154 is a caddisfly; OTU34 is a northeastern moth; OTU150 is a leafroller moth. In other words, this sample contains insects we'd expect in a piece of bat guano (so you can rule out contamination from other guano, say bird guano, from other projects).\n",
    "3. I created another file, **contamprobs.txt** that looks at these top 6 OTUs for all samples. It doesn't fit any single other sample perfectly, but it matches to loads of other samples qualitatively. In other words, plenty of samples contain some number of reads for these OTUs in question, but no single sample has at least 100 reads for every one of these OTUs.  \n",
    "\n",
    "Observation #3 above strongly suggests this being a true sample, though it's unclear whether its a case of a guano sample splitting into the wrong well (as in '**a**') or a true sample that was mislabeled (as in '**b**'). Dropping the OTUs associated with this sample is likely unnecessary. Rather, dropping this sample from further analysis is what makes more sense, as we'd like to retain these OTUs that are present in the data.  \n",
    "\n",
    "This will be done post-taxonomic classification in R, however, if this information was available a priori we could have dropped it earlier with the ** *amptk remove* ** step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll re-run our filtering program this time without that contaminant OTU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amptk filter \\\n",
    "-i bri.cleaned.otu_table.txt \\\n",
    "-f bri.cleaned.otus.fa \\\n",
    "-b mockIM3 \\\n",
    "--keep_mock \\\n",
    "--calculate in \\\n",
    "--mc /leo/devon/projects/guano/mock-fa/CFMR_insect_mock3.fa \\\n",
    "--debug \\\n",
    "--subtract auto \\\n",
    "-o testfilt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "[03:20:07 PM]: OTU table contains 1661 OTUs\n",
    "[03:20:08 PM]: Will use value of 0.500000% for index-bleed OTU filtering.\n",
    "[03:20:08 PM]: Subtracting 48 from OTU table\n",
    "[03:20:19 PM]: Filtering OTU table down to 984 OTUs\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results indicate that our **index-bleed** can be set at **0.05%** (a typical value) and the auto-subtract value can be set to **48**. Note that while this is less of a conservative of a subtract value for one of the two runs (P2 was **47** while P1 was **86**), the fact that we summed up *three* mock communities is potentially artificially inflating our overall counts for any OTU associated with a mock community (despite that fact that we're normalizing reads when making these calculations).\n",
    "\n",
    "Notably, we've increased the number of OTUs retained from our initial filtering (default) parameters when including OTU249. By dropping that single OTU from the dataset we've reduced the **subtract** value by about 900, thus we've recovered the number of OTUs by more than double (we kept **984 OTUs** rather than the earlier **406**).  \n",
    "\n",
    "A final filtering step is applied whereby the mock community reads are removed leaving us with just true samples (and that unknown sample masquerading as a negative control sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amptk filter \\\n",
    "-i bri.cleaned.otu_table.txt \\\n",
    "-f bri.cleaned.otus.fa \\\n",
    "-b mockIM3 \\\n",
    "--calculate in \\\n",
    "--mc /leo/devon/projects/guano/mock-fa/CFMR_insect_mock3.fa \\\n",
    "--subtract auto \\\n",
    "-o bri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments above will produce the following files:  \n",
    "- **filtd.filtered.otus.fa** is the final filtered fasta file (say that five times fast)\n",
    "- **filtd.final.binary.txt** is the presence/absence OTU table after filtering\n",
    "- **filtd.stats.txt** is the number of OTUs in each sample before and after filtering\n",
    "- **filtd.final.txt** is the OTU table with normalized read counts (noramlized to the number of reads in each sample)\n",
    "- **filtd.amptk-filter.log**  \n",
    "\n",
    "The next step is to assign taxonomy by using the **bri.filtered.otus.fa** and **bri.final.binary.txt** files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Assigning Taxonomy to OTUs\n",
    "\n",
    "Make sure to have already downloaded the necessary database (COI). Need to run this command for every instance in which you've generated a uniquely filtered dataset from Parts 1-3. Here's just a pair of examples you'd run in their respective directories:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "amptk taxonomy -i bri.final.binary.txt -f bri.filtered.otus.fa -d COI -o bri"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
