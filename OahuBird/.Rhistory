type(rutmatch.list)
typeof(rutmatch.list)
allmatch.list <- paste(rut.df$BOLDalt, nau.df$BOLDalt, perl.df$BOLDalt, collapse = "")
length(allmatch.list)
allmatch.list <- paste(rut.df$BOLDalt, nau.df$BOLDalt, perl.df$BOLDalt, collapse = ",")
allmatch.list <- c(rut.df$BOLDalt, nau.df$BOLDalt, perl.df$BOLDalt)
allmatch.list <- unique(c(rut.df$BOLDalt, nau.df$BOLDalt, perl.df$BOLDalt))
rm(match.list, naumatch.list, rutmatch.list, perlmatch.list)
ProjectMatches.df <- tmp.df[tmp.df$BOLDalt %in% allmatch.list,]
View(ProjectMatches.df)
allmatch.list <- tmp.list[!tmp.list %in% "none"]
tmp.list <- unique(c(rut.df$BOLDalt, nau.df$BOLDalt, perl.df$BOLDalt))
allmatch.list <- tmp.list[!tmp.list %in% "none"]
allmatch.list <- tmp.list[!tmp.list %in% "none",]
allmatch.list <- tmp.list[!tmp.list %in% none]
tmp.list
tmplist.df <- data.frame(tmp.list)
View(tmplist.df)
tmp2.list <- gsub("none", "", tmp.list)
tmp2.list <- unique(gsub("none", "", tmp.list))
tmp3.list <- gsub("UTAX", "", tmp2.list)
tmp4.list <- gsub("SINTAX", "", tmp3.list)
master.list <- unique(tmp4.list)
allmatch.list <- tmp4.list[tmp4.list != ""]
rm(tmp.list, tmp2.list, tmp3.list, tmp4.list)
rm(master.list)
ProjectMatches.df <- tmp.df[tmp.df$BOLDalt %in% allmatch.list,]
View(ProjectMatches.df)
ProjectMatches.df <- tmp.df[tmp.df$BOLDalt %in% allmatch.list,]
sum(nauProjectMatches.df$CountReads)    # 628,109 ... a big number, but > 500,000 are from just a one OTU (Dicranomyia (Idiopyga) halterella)
sum(ProjectMatches.df$CountReads)    # 628,109 ... a big number, but > 500,000 are from just a one OTU (Dicranomyia (Idiopyga) halterella)
sum(tmp.df$CountReads)
x <- data.frame(allmatch.list)
View(x)
findthis <- c("None", "UTAX", "SINTAX", "CFMR:IM4")
tmpx.list <- gsub(findthis, "", tmp.list)
tmp.list <- unique(c(rut.df$BOLDalt, nau.df$BOLDalt, perl.df$BOLDalt))
findthis <- c("None", "UTAX", "SINTAX", "CFMR:IM4")
tmpx.list <- gsub(findthis, "", tmp.list)
find.list <- list("None", "UTAX", "SINTAX", "CFMR:IM4")
find.string <- paste(unlist(find.list), collapse = "|")
tmpx.list <- gsub(find.string, replacement = "", x = string)
tmpx.list <- gsub(find.string, replacement = "", x = string)
string <- unique(c(rut.df$BOLDalt, nau.df$BOLDalt, perl.df$BOLDalt))
find.list <- list("None", "UTAX", "SINTAX", "CFMR:IM4")
find.string <- paste(unlist(find.list), collapse = "|")
tmpx.list <- gsub(find.string, replacement = "", x = string)
allmatch.list <- tmpx.list[tmpx.list != ""]
rm(string, find.list, find.string, tmpx.list)
rm(findthis, tmp.list)
ProjectMatches.df <- tmp.df[tmp.df$BOLDalt %in% allmatch.list,]
sum(ProjectMatches.df$CountReads)    # 5,338,767 ... a huge number; represents about 2/5 of our overall data (13,950,987 reads)
length(unique(ProjectMatches.df$OTUid))    # 41 unique matches identified
length(unique(tmp.df$OTUid))
tmp_counts <- ProjectMatches.df %>%
group_by(BOLDalt) %>%
count()
tmp_sums <- ProjectMatches.df %>%
group_by(BOLDalt) %>%
summarise(TotalCounts = sum(CountReads))
Match_summary <- merge(tmp_counts, tmp_sums)
rm(tmp_counts, tmp_sums)
rm(x)
rm(tmplist.df)
View(Match_summary)
ggplot(Match_summary, aes(x = TotalCounts, y = n)) + geom_point()
p <- ggplot(Match_summary, aes(x = TotalCounts, y = n))
p + geom_point() +
geom_text(data=subset(Match_summary, TotalCounts > 10000 | n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt))
x <- subset(Match_summary, TotalCounts > 10000 | n > 100)
p + geom_point() +
geom_text(data=subset(Match_summary, n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt))
p + geom_point() +
geom_text(data=subset(Match_summary, TotalCounts > 10000),
aes(x = TotalCounts, y = n, label = BOLDalt))
require(scales)
require(ggplot2)
p + geom_point() +
geom_text(data=subset(Match_summary, TotalCounts > 10000 | n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt)) +
scale_x_continuous(labels = comma)
p + geom_point() +
geom_text(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt)) +
scale_x_continuous(labels = comma)
require(ggrepel)
p + geom_point() +
geom_text(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt), color = 'red') +
scale_x_continuous(labels = comma)
p + geom_point() +
geom_text(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt)) +
geom_point(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt), color = 'red') +
scale_x_continuous(labels = comma)
p + geom_point() +
geom_text(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt)) +
geom_point(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n), color = 'red') +
scale_x_continuous(labels = comma)
p + geom_point() +
geom_text_repel(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt)) +
geom_point(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n), color = 'red') +
scale_x_continuous(labels = comma)
require(ggiraph)
Match_summary$onclick <- paste("http://v4.boldsystems.org/index.php/Public_BarcodeCluster?clusteruri=",
as.character(Match_summary$BOLDalt), sep = "")
q <- p + geom_point() +
geom_text_repel(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt)) +
geom_point(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n), color = 'red') +
scale_x_continuous(labels = comma)
pi <- q + geom_point_interactive()
ggiraph(ggobj = pi, width = 0.7)
data = Match_summary,
mapping = aes(x = TotalCounts, y = n,
tooltip = onclick, data_id = onclick) ) +
geom_point_interactive()
ggiraph(ggobj = gg_point, width = 0.9)
gg_point = ggplot(data = Match_summary,
aes(x = TotalCounts, y = n,
tooltip = onclick, data_id = onclick)) +
geom_point_interactive()
ggiraph(ggobj = gg_point, width = 0.9)
Match_summary$onclick <- sprintf("window.open(\"%s%s\")",
"http://v4.boldsystems.org/index.php/Public_BarcodeCluster?clusteruri=",
as.character(Match_summary$BOLDalt))
q <- p + geom_point() +
geom_text_repel(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt)) +
geom_point(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n), color = 'red') +
scale_x_continuous(labels = comma)
pi = q + geom_point_interactive(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
tooltip = BOLDalt,
onclick = onclick)
pi = q + geom_point_interactive(data=Match_summary,
tooltip = BOLDalt,
onclick = onclick)
pi = ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_point_interactive(data_id = BOLDalt,
tooltip = BOLDalt,
onclick = onclick)
str(Match_summary)
gg_crime <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_point_interactive(
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick ), size = 3 )
ggiraph(code = print(gg_crime), hover_css = "fill-opacity:.3;cursor:pointer;")
gg_crime <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_point_interactive(
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick ), size = 3 )
ggiraph(code = print(gg_crime), hover_css = "fill-opacity:.3;cursor:pointer;")
pi <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_point_interactive(
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick ), size = 3 )
ggiraph(code = print(pi), hover_css = "fill-opacity:.3;cursor:pointer;")
pi <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_text_repel(data=subset(Match_summary, TotalCounts > 200000 | n > 100), aes(x = TotalCounts, y = n, label = BOLDalt)) +
geom_point_interactive(
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick ), size = 3 )
ggiraph(code = print(pi), hover_css = "fill-opacity:.3;cursor:pointer;")
pi <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_point(data=subset(Match_summary, TotalCounts > 200000 | n > 100), aes(x = TotalCounts, y = n), color = 'red') +
geom_point_interactive(
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick ), size = 3 )
ggiraph(code = print(pi), hover_css = "fill-opacity:.3;cursor:pointer;")
pi <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_point_interactive(
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick, color = "red"), size = 3 )
ggiraph(code = print(pi), hover_css = "fill-opacity:.3;cursor:pointer;")
pi <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_point_interactive(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick)), size = 3 )
pi <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_point_interactive(data=subset(Match_summary, TotalCounts > 200000 | n > 100), aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick)), size = 3 )
?geom_point_interactive()
pi <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_point_interactive(
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick), size = 3 )
ggiraph(code = print(pi), hover_css = "fill-opacity:.3;cursor:pointer;")
ggiraph(code = print(pi), hover_css = "fill:red;cursor:pointer;")
ggiraph(code = print(pi), hover_css = "fill:blue;r:7pt")
pi <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_point_interactive(
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick), size = 6 )
ggiraph(code = print(pi), hover_css = "fill:blue;r:7pt")
pi <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
geom_point_interactive(
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick), size = 2 )
ggiraph(code = print(pi), hover_css = "fill:blue;r:7pt")
pi = ggplot(Match_summary, aes(x = TotalCounts, y = n)) +
scale_x_continuous(labels = comma) +
geom_point_interactive(data_id = BOLDalt,
tooltip = BOLDalt,
onclick = onclick)
pi <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) + scale_x_continuous(labels = comma) +
geom_point_interactive(
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick), size = 2 )
ggiraph(code = print(pi), hover_css = "fill:blue;r:7pt")
pi <- ggplot(Match_summary, aes(x = TotalCounts, y = n)) + scale_x_continuous(labels = comma) +
geom_text_repel(data=subset(Match_summary, TotalCounts > 200000 | n > 100), aes(x = TotalCounts, y = n, label = BOLDalt)) +
geom_point_interactive(
aes( data_id = BOLDalt, tooltip = BOLDalt, onclick = onclick), size = 2 )
ggiraph(code = print(pi), hover_css = "fill:blue;r:7pt")
View(nau.df)
View(perl.df)
View(rut.df)
q <- p + geom_point() +
geom_text_repel(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n, label = BOLDalt)) +
geom_point(data=subset(Match_summary, TotalCounts > 200000 | n > 100),
aes(x = TotalCounts, y = n), color = 'red') +
scale_x_continuous(labels = comma)
q
rm(x)
rm(p, q, pi, gg_crime, gg_point)
View(Match_summary)
length(unique(tmp.df$SampleID))
393*2
393*.05
393*.03
setwd("~/Repos/guano/Perlut/data/Routput/")
rut.df <- fread('https://raw.githubusercontent.com/devonorourke/guano/master/Rutgers/master.csv', header = TRUE)
perl.df <- fread('https://raw.githubusercontent.com/devonorourke/guano/master/Perlut/data/Routput/master.csv', header = TRUE)
nau.df <- fread('https://raw.githubusercontent.com/devonorourke/guano/master/NAUsupp/masterdf.csv', header = TRUE)
colnames(nau.df)[3] <- c("BOLDalt")
tmp.df$BOLDalt <- tmp.df$BOLDid
tmp.df <- separate(tmp.df, col = BOLDalt, into = c("BOLDalt", "delete"), sep = "\\.")
tmp.df$delete <- NULL
rut.df$BOLDalt <- rut.df$BOLDid
rut.df <- separate(rut.df, col = BOLDalt, into = c("BOLDalt", "delete"), sep = "\\.")
rut.df$delete <- NULL
string <- unique(c(rut.df$BOLDalt, nau.df$BOLDalt, perl.df$BOLDalt))
find.list <- list("None", "UTAX", "SINTAX", "CFMR:IM4")
find.string <- paste(unlist(find.list), collapse = "|")
tmpx.list <- gsub(find.string, replacement = "", x = string)
allmatch.list <- tmpx.list[tmpx.list != ""]
rm(string, find.list, find.string, tmpx.list)
ProjectMatches.df <- tmp.df[tmp.df$BOLDalt %in% allmatch.list,]
# how many reads here?
sum(ProjectMatches.df$CountReads)    # 5,295,342 ... a huge number; represents about 2/5 of our overall data (13,950,987 reads)
# how many unique OTUs are identified?
length(unique(ProjectMatches.df$OTUid))    # 501 unique matches identified... (our data originally had 1416 OTUs)
## Finally, use that 'nauProjectMatches.df' object and determine how many reads and how frequently are these matches identified in our real data?
tmp_counts <- ProjectMatches.df %>%
group_by(BOLDalt) %>%
count()
tmp_sums <- ProjectMatches.df %>%
group_by(BOLDalt) %>%
summarise(TotalCounts = sum(CountReads))
Match_summary <- merge(tmp_counts, tmp_sums)
rm(tmp_counts, tmp_sums)
setwd("~/Repos/guano/Perlut/data/Routput/")
write.csv(Match_summary, "suspectedContaminants.csv", quote = F)
write.csv(tmp.df, "OahuBird_rawOTUtable.csv", quote = F)
tmp_counts <- tmp.df %>%
group_by(BOLDalt) %>%
count()
tmp_sums <- tmp.df %>%
group_by(BOLDalt) %>%
summarise(TotalCounts = sum(CountReads))
Raw_summary <- merge(tmp_counts, tmp_sums)
rm(tmp_counts, tmp_sums)
View(Raw_summary)
colnames(Raw_summary)[2] <- "Raw_counts"
colnames(Raw_summary)[2:3] <- c("Raw_counts", "Raw_TotalReads"
## those that occur in > 3% of samples (n > 12) with at least 100,000 total reads for that OTU;
## the remainder will be removed from this analysis...
drop.df <- subset(Match_summary, )
## Now let's finally remove those OTUs...
# make a list of OTUs intended to be removed
OTUdrop.list <- nauMatch_summary$BOLDid
# then write a little function and remove them from 'tmp.df' object
'%!in%' <- function(x,y)!('%in%'(x,y))
tmpfilt.df <- tmp.df[tmp.df$BOLDid %!in% OTUdrop.list,]
# note we drop from 10,720 observations to 9.304 observations
# ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~
## We're going to repeat the above process using a different dataset: instead of the NAU project (which was using Central American bat guano) we'll use an earlier North American bat project from Rutgers
rut.df <- fread('https://raw.githubusercontent.com/devonorourke/guano/master/Rutgers/master.csv', header = TRUE)
RutProject.list <- unique(rut.df$BOLDid)    # get a list of unique BOLDid's in project
RutProjectMatches.df <- tmpfilt.df[tmpfilt.df$BOLDid %in% RutProject.list,]    ## Find matches using that list against the 'tmpfilt.df$BOLDid' vector
# how many reads here?
sum(RutProjectMatches.df$CountReads)    # 3,151,857; crap.
# how many unique OTUs are identified?
length(unique(RutProjectMatches.df$OTUid))    # 265 unique matches identified
## Finally, use that 'RutProjectMatches.df' object and determine how many reads and how frequently are these matches identified in our real data?
tmp_counts <- RutProjectMatches.df %>%
group_by(BOLDid) %>%
count()
tmp_sums <- RutProjectMatches.df %>%
group_by(BOLDid) %>%
summarise(TotalCounts = sum(CountReads))
RutMatch_summary <- merge(tmp_counts, tmp_sums)
rm(tmp_counts, tmp_sums)
## the 'nauMatch_summary' object makes it pretty clear: just a couple of OTUs appear to be repeatedly identified in our output, while the ...
## vast majority of contaminants are only every identified once or twice...
## however, it's clear that we can't conclusively determine whether these OTUs are true or artifacts from PCR mix contamination ...
## thus we'll remove all of these OTUs from further analysis; but we'll note a few of these highly occurring taxa and print out this data.frame
setwd("~/Repos/guano/Perlut/data/Routput/")
write.csv(nauMatch_summary, "suspectedContaminants.csv", quote = F)
write.csv(tmp.df, "Perlut_rawOTUtable.csv", quote = F)
## Now let's finally remove those OTUs...
# make a list of OTUs intended to be removed
OTUdrop.list <- nauMatch_summary$BOLDid
# then write a little function and remove them from 'tmp.df' object
'%!in%' <- function(x,y)!('%in%'(x,y))
tmpfilt.df <- tmp.df[tmp.df$BOLDid %!in% OTUdrop.list,]
# note we drop from 10,720 observations to 9.304 observations
# ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~ # ~
## Now let's look back at this filtered table and see how many extraction blanks remain:
## What OTUs are occurring from our extraction NTCs?
## first, subset the data for all 'SampleID' values that match "extBlank" string
NTCs.df <- tmpfilt.df[tmpfilt.df$SampleID %in% matches]
# there are 16 unique observations, just like in the unfiltered 'tmp.df' object; thus the NAU match list didn't affect our NTCs at all! (a bit unexpected)
## After BLASTing each of these OTUs manually there are three OTUs we'll keep and the remaining we'll discard
## this determination was made by examining the read distribution of each OTU among samples; those with all reads less than a few hundred per sample were dropped
## those samples with a few samples >> 1000 reads per sample were retained
NTCdrop.list <- c("OTU83_suspect_mock_chimera",
"OTU98_suspect_mock_chimera",
"OTU104_suspect_mock_chimera",
"OTU397_suspect_mock_chimera",
"OTU149_suspect_mock_chimera",
"OTU166_suspect_mock_chimera",
"OTU167_suspect_mock_chimera",
"OTU178_suspect_mock_chimera",
"OTU222",
"OTU230_suspect_mock_chimera",
"OTU289_suspect_mock_chimera",
"OTU345_suspect_mock_chimera")
tmpfilt2.df <- tmpfilt.df[tmpfilt.df$OTUid %!in% NTCdrop.list,]
# this further reduces our number of 9,304 observations from the NAUmatch-filtered object to 8,438
## What's left to filter?
## remove the remaining OTUs which clearly are contaminants:
# 1. Chiroptera reads and reads assigned to Mock Community sequences
# 2. Other chordates from fish, reptiles, and amphibians (keeping only Arthropod information)
filtdOTUs.df <- subset(tmpfilt2.df, phylum_name == "Arthropoda")
setwd("~/Repos/guano/Perlut/data/Routput/")
write.csv(filtdOTUs.df, "filteredOTUtable.csv", quote = F)
write.csv(contam.df, "contaminantTable.csv", quote = F)
# cleanup...
rm(tmp.df, tmpfilt.df, tmpfilt2.df,
contam_summary, contam.df,
nauMatch_summary, nauProject.df,
NTC_OTU_sums, NTC_summary, NTCs.df,
matches, nauProject.list, NTC_otu.list, OTUdrop.list, toMatch)
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ #
######     Part 3 - incorporating metadata     ######
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ #
## merge with metadata information
# meta.df <- fread('../Perlut_metadata.csv', header = T)
meta.df <- fread('https://raw.githubusercontent.com/devonorourke/guano/master/Perlut/data/Perlut_metadata.csv', header = T)
master.df <- merge(filtdOTUs.df, meta.df)
rm(filtdOTUs.df, meta.df)
## adding hyperlink to link BOLD BIN value to website
master.df$onclick <- paste("http://v4.boldsystems.org/index.php/Public_BarcodeCluster?clusteruri=",
as.character(master.df$BOLDalt), sep = "")
master.df <- master.df[grepl("None", BOLDid), onclick := "no_link_available"];    # when BOLDid not available, removed broken link
# write file to disk:
setwd("~/Repos/guano/Perlut/data/Routput/")
write.csv(master.df, "master.csv", row.names = F, quote = F)
## Notrun: write.table(master.df, "PHINCHmaster.txt", row.names = F, quote = F, sep = "\t")
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ #
######     Part 4 - data analyses     ######
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ #
master.df <- fread('https://raw.githubusercontent.com/devonorourke/guano/master/Perlut/data/Routput/master.csv', header = T)
## load libraries and set working directory to print out data tables:
library(plyr)
setwd("~/Repos/guano/Perlut/data/Routput/")
## following our filtering, how many samples remain with at least 1 OTU? 2 OTUs? 10 OTUs?
OTUperSample = count(master.df, vars = c("SampleID"))   # There are 66 remaining true samples (all NTCs have been filtered out by dropping related OTUs from dataset)
sum(OTUperSample$freq > 1)    # There are 63 samples with at least 2 OTUs
sum(OTUperSample$freq > 4)    # There are 51 samples with at least 4 OTUs
sum(OTUperSample$freq > 9)    # There are 32 samples with at least 10 OTUs
## how many observations of OTUs contain complete information (ie. include 'species_name')... a.k.a. species frequency table
speciesOnly.df <- na.omit(master.df)
freq_species <- as.data.frame(table(speciesOnly.df$species_name))     # frequency table of species detected
colnames(freq_species) <- c("species_name", "counts")
write.csv(freq_species, "species_frq_table.csv", row.names = F, quote = F)
sum(freq_species$counts > 1)  # note 408 species identified, but most are not abundant (no OTU ID'd more than 11 samples)
## how many OTUs are called per site?
OTUperSite = count(master.df, vars = c("NestBox"))
colnames(OTUperSite) <- c("NestBox", "NumberOfDetections")
write.csv(OTUperSite, "OTU_per_Site.csv", row.names = F, quote = F)
## how many OTUs are called per site per week?
OTUperSiteWeek = count(master.df, vars = c("NestBox", "Date"))
colnames(OTUperSiteWeek) <- c("NestBox", "Date", "NumberOfDetections")
write.csv(OTUperSiteWeek, "OTU_per_SiteWeek.csv", row.names = F, quote = F)
setwd("~/Repos/guano/OahuBird/")
h_otutable.df <- fread('https://raw.githubusercontent.com/devonorourke/guano/master/OahuBird/data/amptk/OahuBird_lulu_h.otu_table.taxonomy.txt')
colnames(h_otutable.df)[1] <- ""
## reformat matrix into data.frame, split strings into appropriate columns
h_otutable.df[h_otutable.df == 0] <- NA       # we loaded a binary matrix; all zero's indicate absence of data, all 1's indicate presence of an amplicon
tmp.df <- melt(h_otutable.df)           # converting from wide format to long format (useful for plots)
rm(h_otutable.df)
colnames(tmp.df) <- c("OTUid", "Taxonomy", "SampleID", "CountReads")
tmp.df <- tmp.df[complete.cases(tmp.df),]
tmp.df <- separate(data = tmp.df,
col = Taxonomy,
into = c("TaxMethod", "AlignScore", "BOLDid", "kingdom_name", "phylum_name", "class_name",
"order_name", "family_name", "genus_name", "species_name"),
sep = "\\;|,|\\|")
## reformat taxonomy columns to discard given prefix
tmp.df$kingdom_name <- sub("k:", "", tmp.df$kingdom_name)
tmp.df$phylum_name <- sub("p:", "", tmp.df$phylum_name)
tmp.df$class_name <- sub("c:", "", tmp.df$class_name)
tmp.df$order_name <- sub("o:", "", tmp.df$order_name)
tmp.df$family_name <- sub("f:", "", tmp.df$family_name)
tmp.df$genus_name <- sub("g:", "", tmp.df$genus_name)
tmp.df$species_name <- sub("s:", "", tmp.df$species_name)
## append any of the 'SampleID' values which were actually NTCs (but not labeled as such):
## import target and replacement data.frame:
replace.df <- fread('https://raw.githubusercontent.com/devonorourke/guano/master/OahuBird/data/Rrenamelist.df')
## then use dplyr to make a new column for the replacement matches
tmp2.df <- dplyr::left_join(tmp.df,replace.df, by = "SampleID")
## then substitute any `N/A` value with the original value for those values that didn't have a NTC match:
tmp.df <- within(tmp2.df, X <- ifelse(is.na(replacements), SampleID, replacements))
tmp.df$SampleID <- NULL
tmp.df$replacements <- NULL
colnames(tmp.df)[13] <- "SampleID"
rm(tmp2.df, replace.df)
rut.df <- fread('https://raw.githubusercontent.com/devonorourke/guano/master/Rutgers/master.csv', header = TRUE)
perl.df <- fread('https://raw.githubusercontent.com/devonorourke/guano/master/Perlut/data/Routput/master.csv', header = TRUE)
nau.df <- fread('https://raw.githubusercontent.com/devonorourke/guano/master/NAUsupp/masterdf.csv', header = TRUE)
colnames(nau.df)[3] <- c("BOLDalt")
## Before we can match we need to append the `BOLDid` vectors to remove the "." delimiter in the `tmp.df` and `rut.df` objects:
tmp.df$BOLDalt <- tmp.df$BOLDid
tmp.df <- separate(tmp.df, col = BOLDalt, into = c("BOLDalt", "delete"), sep = "\\.")
tmp.df$delete <- NULL
rut.df$BOLDalt <- rut.df$BOLDid
rut.df <- separate(rut.df, col = BOLDalt, into = c("BOLDalt", "delete"), sep = "\\.")
rut.df$delete <- NULL
## Get a list of all non-redundant `BOLDalt` elements among all three projects:
# because 'none' is not a unique identifier we're removing it from this list
# we're also removing 'CFMR:IM4', 'SINTAX', and 'UTAX' as these were earlier relics of an amptk naming scheme we're not using
string <- unique(c(rut.df$BOLDalt, nau.df$BOLDalt, perl.df$BOLDalt))
find.list <- list("None", "UTAX", "SINTAX", "CFMR:IM4")
find.string <- paste(unlist(find.list), collapse = "|")
tmpx.list <- gsub(find.string, replacement = "", x = string)
allmatch.list <- tmpx.list[tmpx.list != ""]
rm(string, find.list, find.string, tmpx.list)
ProjectMatches.df <- tmp.df[tmp.df$BOLDalt %in% allmatch.list,]
sum(ProjectMatches.df$CountReads)    # 5,295,342 ... a huge number; represents about 2/5 of our overall data (13,950,987 reads)
# how many unique OTUs are identified?
length(unique(ProjectMatches.df$OTUid))    # 501 unique matches identified... (our data originally had 1416 OTUs)
## Finally, use that 'nauProjectMatches.df' object and determine how many reads and how frequently are these matches identified in our real data?
tmp_counts <- ProjectMatches.df %>%
group_by(BOLDalt) %>%
count()
tmp_sums <- ProjectMatches.df %>%
group_by(BOLDalt) %>%
summarise(TotalCounts = sum(CountReads))
Match_summary <- merge(tmp_counts, tmp_sums)
rm(tmp_counts, tmp_sums)
tmp_counts <- tmp.df %>%
group_by(BOLDalt) %>%
count()
tmp_sums <- tmp.df %>%
group_by(BOLDalt) %>%
summarise(TotalCounts = sum(CountReads))
Raw_summary <- merge(tmp_counts, tmp_sums)
rm(tmp_counts, tmp_sums)
colnames(Raw_summary)[2:3] <- c("Raw_counts", "Raw_TotalReads")
View(Raw_summary)
tmp_counts <- tmp.df %>%
group_by(BOLDalt) %>%
count()
tmp_sums <- tmp.df %>%
group_by(BOLDalt) %>%
summarise(TotalCounts = sum(CountReads))
Raw_summary <- merge(tmp_counts, tmp_sums)
rm(tmp_counts, tmp_sums)
tmp_counts <- tmp.df %>%
group_by(BOLDalt) %>%
count()
tmp_sums <- tmp.df %>%
group_by(BOLDalt) %>%
summarise(TotalCounts = sum(CountReads))
tmp_counts <- ProjectMatches.df %>%
group_by(BOLDalt) %>%
count()
tmp_sums <- ProjectMatches.df %>%
group_by(BOLDalt) %>%
summarise(TotalCounts = sum(CountReads))
Match_summary <- merge(tmp_counts, tmp_sums)
rm(tmp_counts, tmp_sums)
View(Match_summary)
tmp_counts <- ProjectMatches.df %>%
group_by(BOLDalt) %>%
count()
View(tmp_counts)
toMatch <- c("^NTC")    # make a list of the regex terms to match
matches <- unique (grep(paste(toMatch,collapse="|"),
tmp.df$SampleID, value=TRUE))   # make a vector of every one of those matches fitting the regex above
NTCs.df <- tmp.df[tmp.df$SampleID %in% matches,]         # capture all matches of regex in 'tmp.df' object
sum(NTCs.df$CountReads)
tmp_counts <- NTCs.df %>%
group_by(SampleID) %>%
count()
tmp_sums <- NTCs.df %>%
group_by(SampleID) %>%
summarise(TotalCounts = sum(CountReads))
NTC_summary <- merge(tmp_counts, tmp_sums)
rm(tmp_counts, tmp_sums)
View(NTC_summary)
View(NTCs.df)
